---
title:        Project Nessie로 데이터 버전 관리하기
date:         2025-01-04
categories:   [Data, Engineering]
tags:         [nessie, iceberg, data lake]
comments:     true
image:
    path:     /assets/img/posts/2025-01-04/main.png
    alt:      project nessie
description:  Apache Iceberg를 사용할 때 데이터의 version control을 돕는 Project Nessie를 살펴보겠습니다.
---

<style>
H2 { color: #298294 }
H3 { color: #1e7ed2 }
H4 { color: #C7A579 }
</style>

## Project Nessie

과거에는 분석 환경에서 데이터가 담긴 파일을 분산 처리하기 위해 주로 Apache Hive를 사용했다. 이때 Hive는 테이블 스키마 등의 메타데이터를 저장하고 API를 통해 저장된 메타데이터 정보를 전달하는 수단, 즉 **카탈로그** 서비스를 위해 Hive metastore를 사용한다.

Project Nessie는 이 Hive metastore를 대체할 수 있는 카탈로그 오픈 소스로서, Apache Iceberg를 사용할 때 엔지니어가 데이터의 버전을 **잘** 관리할 수 있도록 UI 및 API를 제공한다.

Iceberg는 쿼리 엔진이 아니기 때문에, Hive의 알맞은 비교 대상으로 보긴 어렵지만 굳이 차이를 정리해보자면 다음과 같다.

#### Hive vs Iceberg

| - | Hive | Iceberg |
| :---: | --- | --- |
| 유형 | Data Warehouse | Data Lake 용 테이블 포맷 |
| 목적 | 구조화된 데이터를 저장하고 처리하기 위한 플랫폼 | Data Lake에서 신뢰성 있고 효율적인 테이블 관리를 제공 |
| 데이터 저장 | HDFS, S3, GCS 등과 같은 분산 파일 시스템 | 동일 |
| 지원 포맷 | Text, ORC, Parquet Avro | 동일 |
| 메타데이터 저장 | Hive Metastore(RDB) | HDFS, S3 등 Object storage에 저장 |
| 카탈로그 | Hive Metastore | Hive Metastore, AWS Glue, Nessie 등 사용 가능 |
| 데이터 업데이트 | 데이터 삽입, 삭제 시 파일 전체를 다시 작성해야 함 | 데이터 삽입, 삭제 및 병합 작업이 효율적으로 수행 가능 |
| 분산 환경 | Hive Metastore와 MapReduce 중심 | Spark, Flink, Presto와 같은 분산 처리 엔진과 호환 가능 |
| 타임 트래블 | 지원 안 함 | 지원 (과거 스냅샷 조회 가능) |
| 병렬 작업 | 제한적 (충돌 방지 기능이 부족함) | 멀티 브랜칭 및 병합 작업 지원 (Nessie와의 연동으로 더욱 강력해짐) |
| 분석 작업 | 전통적인 배치 처리에 적합 | 실시간 및 배치 처리 모두에 적합 |

## Practice

> 다음 Github 링크에 상세한 설정을 정리해 두었습니다.
> - [https://github.com/ivoryRabbit/play-data-with-docker/tree/master/nessie](https://github.com/ivoryRabbit/play-data-with-docker/tree/master/nessie){: target="_blank"}
{: .prompt-tip }

이제 Docker를 이용해 Iceberg와 Nessie를 테스트할 수 있는 환경을 만들어보자.

우선 Object Storage로는 MinIO를 세팅한다.

```yaml
minio:
    container_name: minio
    image: minio/minio
    ports:
        - "9000:9000"
        - "9001:9001"
    environment:
        MINIO_ROOT_USER: minio
        MINIO_ROOT_PASSWORD: minio123
        MINIO_DOMAIN: minio
    volumes:
        - ./docker/volume/minio:/data
    command: ["server", "/data", "--console-address", ":9001"]
    healthcheck:
      test: ["CMD", "mc", "ready", "local"]
      interval: 10s
      retries: 3
      start_period: 5s
    restart: unless-stopped

minio-client:
    container_name: minio-client
    image: minio/mc
    entrypoint: >
      /bin/bash -c "
        mc config --quiet host add storage http://minio:9000 minio minio123 || true;
        mc mb --quiet --ignore-existing storage/hive || true;
        mc mb --quiet --ignore-existing storage/iceberg || true;
      "
    environment:
      AWS_ACCESS_KEY_ID: minio
      AWS_SECRET_ACCESS_KEY: minio123
      AWS_REGION: ap-northeast-2
      AWS_DEFAULT_REGION: ap-northeast-2
      S3_ENDPOINT: http://minio:9000
      S3_PATH_STYLE_ACCESS: true
    depends_on:
      minio:
        condition: service_healthy
    restart: "no"
```

다음은 카탈로그 역할을 할 Nessie이다. 백엔드로 Postgres, MongoDB 등을 사용할 수 있지만 로컬 개발용 In-memory 기능도 지원한다.

```yaml
nessie:
    container_name: nessie
    image: ghcr.io/projectnessie/nessie:0.101.3
    ports:
      - "19120:19120"
      - "9091:9000"
    environment:
      - nessie.version.store.type=IN_MEMORY
    restart: unless-stopped
```

마지막으로 쿼리 엔진은 Trino 혹은 Dremio를 선택한다. Trino의 경우 `/etc/trino/catalog` 경로에서 Iceberg connector와 Catalog type을 구성할 수 있다.

#### [iceberg.properties]

```conf
connector.name=iceberg

iceberg.catalog.type=nessie
# Trino supports Nessie API V2 as of 450
iceberg.nessie-catalog.uri=http://nessie:19120/api/v2
iceberg.nessie-catalog.ref=main
iceberg.nessie-catalog.default-warehouse-dir=s3://iceberg

fs.native-s3.enabled=true
s3.endpoint=http://minio:9000
s3.region=ap-northeast-2
s3.aws-access-key=minio
s3.aws-secret-key=minio123
s3.path-style-access=true
```

```yaml
trino:
    container_name: trino
    hostname: trino
    image: trinodb/trino:450
    ports:
      - "543:543"
    volumes:
      - ./docker/trino/etc:/etc/trino
      - ./docker/volume/trino:/var/lib/trino/data
    depends_on:
      hive-metastore:
        condition: service_healthy
      nessie:
        condition: service_started
    restart: unless-stopped
```

만약 Apache Dremio를 사용한다면, Trino와 달리 Web에서 Nessie를 등록해야 한다. 참고로 `debug.addDefaultUser=true` 설정을 키면 Web에 접근할 때 Default credential을 사용할 수 있다.

- Username: `dremio`
- Password: `dremio123`

```yaml
dremio:
    container_name: dremio
    image: dremio/dremio-oss:latest
    ports:
      - "9047:9047"
      - "31010:31010"
      - "32010:32010"
    environment:
      - DREMIO_JAVA_SERVER_EXTRA_OPTS=-Dpaths.dist=file:///opt/dremio/data/dis -Ddebug.addDefaultUser=true
    volumes:
      - ./docker/volume/dremio:/op/dremio/data
```

Web에 접속하여 Nessie API URL과 S3 Path를 등록해준다.

![image_01](/assets/img/posts/2025-01-04/image_01.png){: width="800" }

![image_02](/assets/img/posts/2025-01-04/image_02.png){: width="800" }


1912 포트를 이용해 Nessie UI에 접근할 수 있다.
- [http://localhost:19120/tree/main](http://localhost:19120/tree/main){: target="_blank"}

![image_03](/assets/img/posts/2025-01-04/image_03.png){: width="800" }