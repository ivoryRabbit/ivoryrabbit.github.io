---
title:        CUPED - A/B 테스트를 빨리 끝내고 싶다면
date:         2024-12-07
categories:   [Data, Analysis]
math:         true
comments:     true
---

<style>
H2 { color: #298294 }
H3 { color: #1e7ed2 }
H4 { color: #C7A579 }
</style>

---

## A/B 테스트란?

**A/B 테스트**란 사용자 경험 개선을 위해 두 가지의 다른 옵션(A와 B)을 비교하여 최적의 선택을 도출하는 실험 설계 기법이다. 데이터 분석 환경이 갖추어진 많은 회사들이 UI 혹은 알고리즘을 개선할 때 A/B 테스트를 이용해 의사결정하고 있다.

통계학에서는 **가설 검정**이란 이름으로 더 잘 알려져 있는데, 온라인 실험 환경에서 데이터 기반 의사결정을 목적으로 수행되는 경우에 특별히 A/B 테스트라고 부르는 듯 하다.

이해를 돕기 위해 웹 사이트에서 버튼 색상을 변경했을 때 클릭률(Click-Through Rate, CTR)에 어떤 영향을 미치는지 분석하는 상황을 가정해보자.

| 유형 | 설명 | 표본 수 | CTR |
| :--- | :--- | ---: | ---: |
| 대조군(A) | 흰색 배경에 회색 버튼 | 100 | 13% |
| 실험군(B) | 흰색 배경에 빨간색 버튼 | 100 | 15% |

빨간색 버튼의 CTR이 회색 버튼보다 높으므로 우리는 실험 결과를 토대로 버튼 색깔을 빨간색으로 교체하도록 결정을 내릴 수 있다.

### p-value

하지만 이렇게 결론 내려도 문제가 없는걸까? 다시 의사결정 과정으로 되돌아가보자.

기존에는 회색 버튼을 사용하고 있었기 때문에 최악의 상황은 바로 <u>버튼 색깔을 바꾸었음에도 불구하고 CTR이 감소</u>하는 것이다. 따라서 우리는 긍정이라 판단했지만 실제론 아닌 경우(False Positive, FP)에 유의하여 의사결정을 해야 했다.

| 결정\결과 | CTR 상승 | CTR 유지 | CTR 감소 |
| --- | :--- | :--- | :--- |
| 색깔 유지(N) | - | 당연함(TN) | - |
| 색깔 교체(P) | 뿌듯함(TP) | 아쉬움(FP) | 최악(FP) |

다행히도 고등학교에서 이를 1종 오류라고 정의하고 정량적으로 측정할 수 있는 수단을 배웠~~었~~는데, 바로 **p-value**이다. p-value는 실험군의 데이터가 대조군의 분포로부터 관측될 확률을 의미한다.

p-value가 높을수록 실험군의 통계값을 신뢰하기 어렵기 때문에, 실험 전에 미리 정해둔 **유의수준**을 넘겼다면 실험 결과를 의사결정에 사용하는데 주의를 기울여야 한다.

Python을 이용해 예시에서의 p-value를 한번 계산해보자.

```python
from scipy.stats import binomtest

test = binomtest(k=15, n=100, p=0.13, alternative="greater")
print(f"p-value: {test.pvalue:0.3f}")
```

#### [실행 결과]
```
p-value: 0.317
```

보통 유의수준을 0.05 ~ 0.10 사이로 설정한다는 점을 고려해보면, 0.317이라는 수치는 너무 높다. 따라서 해당 실험의 결과를 신뢰하기는 아직 어려울 것이다.

### z-test

앞선 실험에서는 클릭률을 살펴봤었지만, A/B 테스트에서 표본 집단의 확률 분포가 꼭 Binomial 일리란 법이 없다. 그러나 중심 극한 정리(Central Limit Theorem, CLT) 덕분에 표본 수가 적당히 클 때(n > 30) 표본 평균의 확률 분포를 정규 분포로 가정할 수 있다.

$$ \bar{X} \sim N(\bar{\mu}, \bar{\sigma}^2) $$

여기서 모집단의 평균과 분산이 각각 $\mu$, $\sigma$이고 표본 개수가 $n$일 때, 표본 평균의 통계량은 다음과 같다.

$$\bar{\mu} = \mu$$

$$\bar{\sigma}=\frac{\sigma^2}{n}$$

이 가정 하에 z-test를 수행하면 다음과 같은 결과를 얻는다.

$$ Z = \frac{\bar{X} - \bar{\mu}}{\bar{\sigma}}$$

```python
from scipy.stats import norm

mean = 0.13
std = (1/100 * 0.13 * (1-0.13)) ** 0.5
z_score = (0.15 - mean) / std

p_value = 1 - norm.cdf(z_score)
print(f"p-value: {p_value:0.3f}")
```

#### [실행 결과]
```
p-value: 0.276
```

### t-test

사실 A/B 테스트에서 모집단의 확률 분포를 모르는 경우가 많다. 이럴땐 어쩔 수 없이 표본집단으로부터 모집단의 통계량을 추정할 수 밖에 없는데, 이를 **추정량**(estimator)이라고 부른다. 그리고 그 기대값이 모집단의 통계량과 같은 경우(unbiased esimator)를 주로 사용한다.

표본 평균의 기대값은 다행히 모집단의 평균 $\mu$와 동일하고 표본 분산의 기대값은 모집단 분산의 $\frac{n-1}{n}$ 배 이므로, 수식을 약간 수정하여 unbiased estimator를 계산해낼 수 있다.

$$\hat{\mu} = \bar{\mu}$$

$$\hat{\sigma}^2 = \frac{n}{n-1}\bar{\sigma}^2$$

모집단의 분산 대신 추정량을 사용하면 더 이상 정규 분포를 가정할 수 없다. 따라서 모집단의 분산을 모르는 경우에는 t 분포를 사용해야 한다.

$$ t = \frac{\bar{X} - \hat{\mu}}{\hat{\sigma}} $$

```python
from scipy.stats import t

mean_a, std_a, nobs_a = 0.13, (1/99 * 0.13 * (1-0.13)) ** 0.5, 100
mean_b, std_b, nobs_b = 0.15, (1/99 * 0.15 * (1-0.15)) ** 0.5, 100


se = (std_a ** 2 + std_b ** 2) ** 0.5
t_score = (mean_b - mean_a) / se
df = min(nobs_a -1, nobs_b -1)

pvalue = 1 - t.cdf(t_score, df=df)
print(f"p-value: {pvalue:0.3f}")
```

#### [실행 결과]
```
p-value: 0.343
```


### Variance

(WIP)

표본 수가 많아지면 분산이 작아진다.

분산이 작아지면 t-score가 커진다.

t-score가 커지면 p-value가 작아진다.

## CUPED

CUPED(Controlled Using Pre-Existing Data)

A/B 테스트 결과의 분산(variance)이 높을 경우 통계적으로 유의미한 결과를 얻기 위해 더 큰 표본 크기가 필요하거나, 분석의 신뢰도가 낮아질 수 있다. **CUPED (Controlled Using Pre-Existing Data)**는 이러한 문제를 해결하기 위해 고안된 통계적 기법으로, 실험 전에 수집된 데이터를 활용하여 결과의 변동성을 줄이고 검출력을 높인다.

논문에 따르면 CUPED는 분산을 약 50% 까지 줄이기 때문에 실험 기간 또한 절반으로 줄일 수 있다고 주장하고 있다.

#### [논문 링크]

- [Improving the Sensitivity of Online Controlled Experiments by Utilizing Pre-Experiment Data](https://exp-platform.com/Documents/2013-02-CUPED-ImprovingSensitivityOfControlledExperiments.pdf){: target="_blank"}

CUPED는 추정량의 분산을 줄이기 위해 다음 두 가지 Monte-Carlo sampling을 사용한다.

1. Control Variates Method

사전 데이터(Covariate)를 사용하여 분산을 줄인다. (correlation이 클수록 분산이 더 작아짐)

실험 시작 이전의 데이터를 사전 데이터로 채택한다.

2. Stratification Method

표본 집단을 더 잘게 쪼개어 각각의 평균을 추정량으로 선택한다.

실험 시작 이전의 데이터에 포함된 유저 / 포함되지 않은 신규 유저 / 이탈 유저


