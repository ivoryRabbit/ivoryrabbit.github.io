---
title:        DBT 굉장하다
date:         2024-02-18
categories:   [Data, Engineering]
comments:     true
---

<style>
H2 { color: #298294 }
H3 { color: #1e7ed2 }
H4 { color: #C7A579 }
</style>

## DBT

DBT란 Data Build Tool의 약자로, "모델"을 데이터 처리에 필요한 코드를 모듈화하고 데이터의 품질 관리를 돕는 워크플로우 도구이다. 분석 환경으로 데이터가 Ingestion 되고 나면, 데이터 분석가들은 이로부터 유의미한 비지니스 지표를 뽑아 내기 위해 대단히 많은 쿼리를 생성하고 실행하게 된다. 이때 분석가들이 엔지니어 도움 없이도 쉽게(?) 분석 결과를 테이블로 생성할 수 있도록 하는 것이 DBT의 목표라고 한다. ~~아니 해보니까 어렵던데~~

DBT를 이용하면 매번 반복되는 DML과 DDL를 작성할 필요 없이 재사용 가능한 SQL들을 생성하고 문서로 관리할 수 있다. 또 의존 관계를 정의하고 시각화 할 수 있어 어려운 비지니스 로직을 작성하더라도 실수할 여지를 줄일 수 있다. 마지막으로 버저닝 및 환경 분리를 위한 프로파일을 지원하고 있어 프로덕션에 배포하기 전에 비지니스 로직과 데이터 품질을 테스트해 볼 수 있다.

DBT는 Cloud 서비스 뿐만 아니라 Github의 오픈소스로도 공개되어 있다.
- [dbt-core](https://github.com/dbt-labs/dbt-core){: target="_blank"}

대략 2년 전 쯤 지인을 통해 처음 알게 되었는데, 최근 들어 많은 회사에서 도입하고 있다는 소식을 듣고 공부를 시작하였다. 직접 작업을 해보면서 느꼈던 DBT의 장단점들과 해볼만한 고민들을 이 글을 통해 공유하고자 한다. DBT에서 등장하는 개념들이 생각보다 어렵기 때문에  

### Profiles

가장 먼저 **profiles.yml** 파일에 대한 이해가 필요하다. 이 파일에는 쿼리를 실행시킬 데이터 소스를 개발 환경 별로 정의할 수 있다. 보통은 `~/.dbt` 디렉토리가 생성되면서 그 아래에 위치한다. 환경 변수나 argument를 주입하여 다른 디렉토리로 위치시켜 사용 가능하다.

```yaml
trino:
  target: dev
  outputs:
    local:
      type: trino
      host: localhost
      port: 8080
      user: admin
      password:
      catalog: hive
      schema: default
    dev:
      type: trino
      host: trino-dev
      port: 543
      user: admin
      password:
      catalog: hive
      schema: default
    prod:
      type: trino
      host: trino-dev
      port: 543
      user: admin
      password:
      catalog: hive
      schema: default
```

- 가장 상단의 "trino"는 프로필의 이름이다. DBT docs에서는 조직 이름을 사용하기를 권장하고 있다.
- "target"은 쿼리를 실행시킬 때 디폴트로 사용할 환경이다. 예시에서는 "outputs" 아래의 ["local", "dev", "prod"] 중 하나가 돼야 한다.
- "outputs"는 데이터 소스의 config이다. 예시와 달리 상황에 맞게 다른 이름을 사용해도 된다. (ex: "staging", "test" 등)

### Projects

개인적으로 **dbt_project.yml** 파일이 DBT의 러닝커브를 높이고 있는 원흉 중 하나라고 생각한다. 단순히 yaml을 선언하는 것 뿐만 아니라 다른 파일들과의 경로 관계도 신경 써주어야 한다. 만약 dbt를 설치하고 `dbt init`을 실행시킨다면 기본적으로 다음과 같은 디렉토리 구조가 제공된다.

```plain text
dbt_airflow
├── analyses
├── tests
├── seeds
├── macros
├── snapshots
├── models
│   └── dev
│       ├── my_first_dbt_model.sql
│       ├── my_second_dbt_model.sql
│       └── schema.yml
└── dbt_project.yml
```

```yaml
# 1
name: "dbt_airflow"
version: "1.0.0"
config-version: 2
require-dbt-version: [ ">=1.7.1", "<=1.7.7" ]

# 2
profile: "trino"

# 3
model-paths: ["models"]
analysis-paths: ["analyses"]
test-paths: ["tests"]
seed-paths: ["seeds"]
macro-paths: ["macros"]
snapshot-paths: ["snapshots"]

# 4
models:
  dbt_airflow:
    +on_table_exists: drop
    dev:
      +materialized: table # view, table, ephemeral, Incremental

seeds:
  dbt_airflow:
    +full_refresh: true
```

1. DBT 프로젝트 이름 및 버전
2. 프로젝트에서 사용할 프로파일 이름
3. 프로젝트가 가리키는 각종 "리소스"들의 파일 경로
4. "리소스" 별 config

### Resources

#### Seed

해당 경로 아래에 있는 csv 파일들을 등록된 데이터 소스로 업로드 한다. 뜯어보면 데이터를 청크로 나누어 동기적으로 Insert를 날리고 있기 때문에 데이터의 크기가 조금만 커도 엄청 오래 걸린다. 운영 환경에서는 절대 사용하지 말아야 한다.

#### Model

DBT로 처리할 테이블들을 정의하는 곳이다. 테이블 스키마와 간단한 검증 규칙들을 yaml로 선언할 수 있다.

#### Snapshot

테이블의 변경 사항을 history 형태로 남기고 싶을 때 사용한다. 보통 SCD(Slowly Changing Dimension) 테이블인 경우 유용하며, 데이터의 추가나 수정이 언제 발생했는지 알 수 있도록 `dbt_valid_from`과 `dbt_valid_to` 라는 두 컬럼이 붙은 새로운 테이블을 생성한다.

#### Macro

jinja template으로 UDF(User Defined Function)을 만들 수 있다.

#### Analysis

실제 테이블은 만들지 않고 `dbt compile`을 통해 SQL을 생성해준다. yaml 파일에서 jinja template으로 선언한 모델을 실행 가능한 SQL 형태로 바꾸는 용도이다.

#### Test

ㅋ

## Practice

> 다음 Github 링크에 상세한 설정을 정리해 두었습니다.
> - [https://github.com/ivoryRabbit/play-data-with-docker/tree/master/dbt](https://github.com/ivoryRabbit/play-data-with-docker/tree/master/dbt){: target="_blank"}
{: .prompt-tip }

도커를 이용해 다음과 같은 환경을 띄워보려 한다.

![image_01](/assets/img/posts/2024-02-18/image_01.png){: width="800" height="400" }

### 1. Trino

### 2. Airflow

### 3. DBT